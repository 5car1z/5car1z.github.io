<!DOCTYPE html><html><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="description" content="Linux System Administration"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="alternative" href="atom.xml" title="Tricks of the Trades" type="application/atom+xml"><link rel="icon" href="/favicon.png"><title>Programming - Tricks of the Trades</title><link rel="stylesheet" href="/css/main.css"><!--[if lt IE 9]><script>(function(a,b){a="abbr article aside audio bdi canvas data datalist details dialog figcaption figure footer header hgroup main mark meter nav output progress section summary template time video".split(" ");for(b=a.length-1;b>=0;b--)document.createElement(a[b])})()</script><![endif]--></head><body><header class="head"><h1 class="head-title u-fl"><a href="/">Tricks of the Trades</a></h1><nav class="head-nav u-fr"><ul class="head-nav__list"><li class="head-nav__item"><a href="/" class="head-nav__link">Home</a></li><li class="head-nav__item"><a href="/trades" class="head-nav__link">Trades</a></li><li class="head-nav__item"><a href="/archives" class="head-nav__link">Archives</a></li><li class="head-nav__item"><a href="/work" class="head-nav__link">Work</a></li><li class="head-nav__item"><a href="/about" class="head-nav__link">About</a></li><li class="head-nav__item"><a href="/contact" class="head-nav__link">Contact</a></li></ul></nav></header><main class="main"><article class="post"><header class="post__head"><time datetime="2016-04-25T23:00:00.000Z" class="post__time">April 26, 2016</time><h1 class="post__title"><a href="/2016/04/26/github-flow/">Git Version Control - Contributing to GitHub Projects (3)</a></h1></header><div class="post__main echo"><p><img src="http://i.imgur.com/HLLz1Wv.png" alt="Octocat!"></p>
<h1 id="Preamble"><a href="#Preamble" class="headerlink" title="Preamble"></a>Preamble</h1><p>GitHub is one of the most popular ways to contribute to open-source projects. Many major and minor organisations keep their open-source code-base hosted there, adopting the idea that anyone who follows the rules can have their own efforts put up for consideration. This post talks about said process, which if anything is referred to as “GitHub Flow”.   </p>
<p>This information as presented by GitHub is readily available in various forms within their <a href="https://guides.github.com/" target="_blank" rel="external">“GitHub Guides”</a> documentation. More specific links to these are listed at the end of the post. </p>
<blockquote>
<p><strong>“As of April 2016, GitHub reports having more than 14 million users and more than 35 million repositories, making it the largest host of source code in the world.”</strong></p>
</blockquote>
<a id="more"></a>
<hr>
<h1 id="Github-Flow"><a href="#Github-Flow" class="headerlink" title="Github Flow"></a>Github Flow</h1><p>Summarised, the general concept here in terms of public contributions is to:</p>
<ol>
<li>Fork, then create a suitable topic branch from master.</li>
<li>Make some commits to improve the project.</li>
<li>Push the branch to the forked GitHub project.</li>
<li>Open a Pull Request for merging on the original GitHub repo.</li>
<li>Discuss, and optionally continue committing.</li>
<li>The project owner then merges or closes the Pull Request.</li>
</ol>
<p>The upcoming sections cover these steps in more detail.</p>
<p>This PDF gives a loose impression of how the “flow” process would apply in the context of a formal team working on their project (i.e. the non public workflow): </p>
<object data="https://guides.github.com/pdfs/githubflow-online.pdf#" type="application/pdf" width="100%" height="900"><br><br><p>It appears your Web browser is not configured to display PDF files.<br>No worries, just <a href="https://guides.github.com/pdfs/githubflow-online.pdf" target="_blank" rel="external">click here to download the PDF file.</a></p><br><br></object>

<hr>
<h1 id="Public-Pull-Requests"><a href="#Public-Pull-Requests" class="headerlink" title="Public Pull Requests"></a>Public Pull Requests</h1><p>Outside of an internal team back in the public domain, we return to the steps summarised before. These are now covered in greater detail and do not mirror the steps above completely as these are laid out in a more practical manner. </p>
<h2 id="1-–-Fork-Repository"><a href="#1-–-Fork-Repository" class="headerlink" title="1 – Fork Repository"></a>1 – Fork Repository</h2><p><img src="https://i.gyazo.com/7776cde860e0215dacab1fd81d53894a.png" alt="Flow - Step 1"></p>
<p>The first step is to find the project on GitHub you want to contribute to, then read through any guidelines they may have in the <code>CONTRIBUTING</code> file, or similarly named. These guidelines are usually code conventions/syntax, feature requests, or nuances specific to the project. </p>
<p>Project’s often have wiki’s containing information along these lines too (especially the larger ones). This can be accessed from the top of the project page tabs, if it exists. </p>
<p>Once selected, the next step is to <em>fork</em> the repository by clicking the aptly named button. You must be signed into your GitHub account when doing this.</p>
<p>Here’s a picture of what the button looks like:</p>
<p><img src="https://git-scm.com/book/en/v2/book/06-github/images/forkbutton.png" alt="GitHub Fork Button"></p>
<p>After a few seconds, you’re taken to your own forked version of the repository. In which everything you do is now separate to the original project.</p>
<blockquote>
<p><a href="https://help.github.com/articles/fork-a-repo/" target="_blank" rel="external">Pro Git Book - Forking Projects</a></p>
</blockquote>
<hr>
<h2 id="2-–-Sync-Fork"><a href="#2-–-Sync-Fork" class="headerlink" title="2 – Sync Fork"></a>2 – Sync Fork</h2><p>Any updates or commits that get added to the original repository by the maintainers won’t be included in your fork, so they need to be retrieved and merged. This is so that when it comes to offering up your own changes, they’re in the context of the up to date target project. </p>
<p>This syncing may not be required right now, but once future commits are made to the <em>upstream</em> repository, you’ll need to pull them into your own fork so it’s kept up to date. </p>
<p>Clone your forked repository locally then add the original upstream repository as a remote.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git remote add upstream https://github.com/ORIGINAL_OWNER/ORIGINAL_REPOSITORY.git</span><br></pre></td></tr></table></figure>
<p>Confirm success with:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git remote -v</span><br></pre></td></tr></table></figure>
<p>Fetch the branches and their respective commits from the <code>upstream</code> repository. </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git fetch upstream</span><br></pre></td></tr></table></figure>
<p>Ensure you’re on the <code>master</code> branch.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git checkout master</span><br></pre></td></tr></table></figure>
<p>Upstream commits to <code>master</code> are now stored in a local branch named <code>upstream/master</code> . </p>
<p>Merge the changes from <code>upstream/master</code> into your local <code>master</code> branch; this doesn’t automatically lose any of your own local changes.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git merge upstream/master</span><br></pre></td></tr></table></figure>
<p>Assuming there are no merge conflicts you are then safe to push these to your own fork’s remote repo.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git push origin master</span><br></pre></td></tr></table></figure>
<p>This completes the syncing process, but the merge will need to be carried out each time you want to update your own fork with the original repo’s new commits. </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ git fetch upstream</span><br><span class="line">$ git checkout master</span><br><span class="line">$ git merge upstream/master</span><br><span class="line">$ git push origin master</span><br></pre></td></tr></table></figure>
<p>A secondary method where you manually <code>pull</code> in the updates is also available, and the steps for it are described <a href="https://help.github.com/articles/merging-an-upstream-repository-into-your-fork/#platform-linux" target="_blank" rel="external">here</a>.</p>
<blockquote>
<p><a href="https://help.github.com/articles/configuring-a-remote-for-a-fork/" target="_blank" rel="external">GitHub Help - Configuring a Remote For a Fork</a><br><a href="https://help.github.com/articles/syncing-a-fork/" target="_blank" rel="external">GitHub Help - Syncing a Fork</a></p>
</blockquote>
<hr>
<h2 id="3-–-Make-Changes-on-New-Branch"><a href="#3-–-Make-Changes-on-New-Branch" class="headerlink" title="3 – Make Changes on New Branch"></a>3 – Make Changes on New Branch</h2><p><img src="https://i.gyazo.com/0e84174ca44be84d385dd7c7055d79d2.png" alt="Flow - Step 2"></p>
<p>Creating a new branch based off of the master branch and then implementing your changes in there, is good practice when working on a project. It’s possible to make changes directly to the master branch, but even just for the sake of etiquette, avoid doing this. It also means you can push follow-up commits if you need to update the future pull request.</p>
<p>Your branch names should be descriptive (e.g. refactor-authentication, user-content-cache-key, make-retina-avatars) etc. </p>
<p>Create a new branch with <code>-b</code> and a suitable name.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git checkout -b branch_name</span><br></pre></td></tr></table></figure>
<p>From here on you’re good to make the changes and improvements you need for your eventual Pull Request. </p>
<p>Remember to add, commit, and push your branch changes to the remote version of the fork once finished. </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ git add .</span><br><span class="line">$ git commit -m <span class="string">"message"</span></span><br><span class="line">$ git push origin branch_name</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="4-–-Create-Pull-Request"><a href="#4-–-Create-Pull-Request" class="headerlink" title="4 – Create Pull Request"></a>4 – Create Pull Request</h2><p><img src="https://i.gyazo.com/1e20c1f9ad9618972aa7e78fdbf85337.png" alt="Flow - Step 3"></p>
<p>Pull requests allow the original project’s maintainer(s) to compare your branch to their existing master branch, and decide whether or not to incorporate (merge) your changes.</p>
<p>You can open a Pull Request at any point during the development process, but ideally should be when you’re ready for someone to review your work. Using GitHub’s “@mention” system in your Pull Request message means you can target specific people or teams for feedback, as they’ll be individually notified. </p>
<p>Click the green “New Pull Request” button on your GitHub fork webpage, and you’ll see a screen that compares the two target repositories. Add as much detail as possible to the Pull Request description to make clear the changes.</p>
<p><img src="https://git-scm.com/book/en/v2/book/06-github/images/blink-03-pull-request-open.png" alt="Pro Git Book - Create Pull Request View"></p>
<p>When you hit “Create Pull Request” to confirm - the project owners of the original repo will get a notification that someone has suggested a new changes or features, and get access to the summary of the request. </p>
<blockquote>
<p><a href="https://help.github.com/articles/using-pull-requests/" target="_blank" rel="external">GitHub Help - Using Pull Requests</a></p>
</blockquote>
<hr>
<h2 id="5-–-Discuss-Changes"><a href="#5-–-Discuss-Changes" class="headerlink" title="5 – Discuss Changes"></a>5 – Discuss Changes</h2><p><img src="https://i.gyazo.com/48268c6e0a225557ac97ca1ca1714aee.png" alt="Flow - Step 4"></p>
<p>Pull Requests often initiate discussion about your proposed changes. This comes in the form of he maintainer or his team asking questions and suggesting further improvements. Other users on GitHub can see the Pull Request details too, and may chime in - the review process is not limited to just official project members.</p>
<blockquote>
<p><strong>“Pull Requests are designed to encourage and capture this type of conversation.”</strong></p>
</blockquote>
<p>If you are asked to make some changes to your Pull Request, simply add new commits to your dedicated branch locally and push them again. These get automatically placed into the existing Pull Request.</p>
<p>On a final note here user comments are written in Markdown, and you can embed images, emoji, use pre-formatted code blocks, and add other supported formatting. Remember the “@mention” system too. </p>
<hr>
<h2 id="6-–-Testing-Optional"><a href="#6-–-Testing-Optional" class="headerlink" title="6 – Testing (Optional)"></a>6 – Testing (Optional)</h2><p><img src="https://i.gyazo.com/01f4248fb138526a54c021a898a34069.png" alt="Flow - Step 5"></p>
<p>This is generally not something you have to worry about; unless you’ve been asked to include/run some unit tests in your changes. Most of the other “production” tests that verify whether your changes work in a live environment or not (TravisCI, Jenkins, etc), are run by the maintainer and performed automatically. </p>
<p>As long as these pass you’re fine. If the branch commits do causes issues you should amend your work as instructed by a maintainer - in the same manner as before. </p>
<hr>
<h2 id="7-–-Pull-Request-Merges-Closes"><a href="#7-–-Pull-Request-Merges-Closes" class="headerlink" title="7 – Pull Request Merges/Closes"></a>7 – Pull Request Merges/Closes</h2><p><img src="https://i.gyazo.com/098018f3096144cbc5bf434f98c4aff2.png" alt="Flow - Step 6"></p>
<p>Now that your changes have been approved, maybe iterated on, and tested to work in production, your Pull Request <strong>may</strong> get merged. </p>
<p>If your Pull Request gets merged by the end of it all  that’s great. If not there was probably good reason. Take any feedback you receive and don’t worry about it too much - it happens a lot. </p>
<p>If merged successfully however, the Pull Request is preserved and a record of the changes become a part of the project’s Git history.</p>
<hr>
<h1 id="Collaborator-Method"><a href="#Collaborator-Method" class="headerlink" title="Collaborator Method"></a>Collaborator Method</h1><p>There are despite all the above not just one but two methods of contributing to a project. When working as part of a team on GitHub or organisation, things become a bit easier and less informal. The PDF from the “Flow” section applies more here too, but not completely as a team could still be comprised of public users. </p>
<h2 id="1-–-Become-a-Collaborator"><a href="#1-–-Become-a-Collaborator" class="headerlink" title="1 – Become a Collaborator"></a>1 – Become a Collaborator</h2><p>Owners of a repository can add more users to work as “collaborators” for the project. Giving them read and write permissions to a repository.  Repositories owned by GitHub “organisations” have more controls over granting collaborators permissions. </p>
<p>In general though users can be added as collaborators under your repository’s “Settings” page, by clicking the “Collaborators &amp; teams” tab. Then entering the username you wish to add into the search field.</p>
<p><img src="https://help.github.com/assets/images/help/repository/repo-settings-collab-autofill.png" alt="Collaborators Search Field"></p>
<p>Giving them write privileges should they need them, and clicking the “Add collaborator” button to confirm.  </p>
<blockquote>
<p><a href="https://help.github.com/categories/managing-repository-collaborators/" target="_blank" rel="external">GitHub Help - Managing Repository Collaborators</a></p>
</blockquote>
<hr>
<h2 id="2-–-Clone-Repository"><a href="#2-–-Clone-Repository" class="headerlink" title="2 – Clone Repository"></a>2 – Clone Repository</h2><p>The targeted collaborator can now clone the repo to make changes and improvements to it.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git <span class="built_in">clone</span> https://github.com/username/repository-name.git</span><br></pre></td></tr></table></figure>
<p>Notice there is no need to fork the repository like previously as any changes committed and pushed will be instantly merged and approved into the remote version on GitHub. </p>
<hr>
<h2 id="3-–-Make-Changes"><a href="#3-–-Make-Changes" class="headerlink" title="3 – Make Changes"></a>3 – Make Changes</h2><p>As before make your changes in the same way (still abiding by the new branch workflow). </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git checkout -b branch_name</span><br></pre></td></tr></table></figure>
<p>But remember if changing contents of the master branch, that these are merged instantly when pushed. Any errors/mistakes can be reverted or undone thanks to Git, but still be careful as the master branch is often used for live deployment setups and in conjunction with the automated CI tools mentioned earlier. </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ git add .</span><br><span class="line">$ git commit -m <span class="string">"messsage"</span></span><br><span class="line">$ git push origin branch_name</span><br></pre></td></tr></table></figure>
<p>Consider the next two options available to you after pushing. </p>
<hr>
<h2 id="Option-A-–-Merge-Changes"><a href="#Option-A-–-Merge-Changes" class="headerlink" title="Option A – Merge Changes"></a>Option A – Merge Changes</h2><p>There are two options on offer to you once you have your feature or fixes committed and pushed to the new remote branch. </p>
<p>If you’re confident the work can be merged into master, and happy to fix any merge conflicts yourself (and also have the permissions). Then you can merge the changes on the command line. </p>
<p>Before merging make sure you are on the master branch and it’s up to date locally. </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git checkout master</span><br><span class="line">$ git pull origin master</span><br></pre></td></tr></table></figure>
<p>Merge the new target branch into master.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git merge branch_name</span><br></pre></td></tr></table></figure>
<p>Fix any merge conflicts and push the changes to the remote master branch on GitHub. </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git push origin master</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="Option-B-–-Create-Pull-Request"><a href="#Option-B-–-Create-Pull-Request" class="headerlink" title="Option B – Create Pull Request"></a>Option B – Create Pull Request</h2><p>An alternative choice and one better suited to those who want approval or simply for other team members to first see their proposed merges - is to instead create a pull request that visualises the process, and shows up on GitHub. </p>
<p>After pushing the branch to GitHub’s remote repo, a new “Compare &amp; pull request” button appears on the project page:</p>
<p><img src="https://i.gyazo.com/2767fdac556f907d3bb77f0d8703415f.png" alt="Compare &amp; pull request Button"></p>
<p>If this is not present the usual “New pull request” button is available to compare the two branches, with the view to merging.  </p>
<p><img src="https://i.gyazo.com/cf3c19b47ab83c86bc88270b9ba57597.png" alt="New pull request Button"></p>
<p>Either way this new request can be commented on, verified, improved further and resolved of any merge conflicts before merging. Which can be done by someone else in the team who has the permissions or power of approval. All thorough GitHub like in the case of a regular public pull request. </p>
<p><img src="https://i.gyazo.com/84b2b2c365ee221affd3838d6bd551ab.png" alt="Merge pull request Button"></p>
<hr>
<h2 id="Protected-Branches"><a href="#Protected-Branches" class="headerlink" title="Protected Branches"></a>Protected Branches</h2><p>One last point worth mentioning that revolves around collaborators and teams is the concept of “Protected Branches”. This idea ensures that approved collaborators cannot make irrevocable changes to branches on repositories. This is intended to keep your project and pull requests organised and safe. </p>
<p>Specifically these administrator designated branches cannot be force pushed, cannot be deleted, and cannot have changes merged into them until required status checks have passed. </p>
<blockquote>
<p><a href="https://help.github.com/articles/about-protected-branches/" target="_blank" rel="external">GitHub Help - About Protected Branches</a><br><a href="https://help.github.com/articles/configuring-protected-branches/" target="_blank" rel="external">GitHub Help - Configuring Protected Branches</a></p>
</blockquote>
<p><a href="http://www.tricksofthetrades.net/trades/">Links to subsequent Git posts can be found on the Trades page.</a></p>
<hr>
<p><strong>More Information</strong></p>
<ul>
<li><a href="https://guides.github.com/activities/contributing-to-open-source/" target="_blank" rel="external">GitHub Guides - Contributing to Open Source on GitHub</a></li>
<li><a href="https://guides.github.com/introduction/flow/index.html" target="_blank" rel="external">GitHub Guides - Understanding the GitHub Flow</a></li>
<li><a href="https://git-scm.com/book/en/v2/GitHub-Contributing-to-a-Project" target="_blank" rel="external">Pro Git Book - Contributing to a Project</a></li>
</ul>
<blockquote>
<p>Easily deploy an SSD cloud server on <a href="https://www.digitalocean.com/?refcode=e91058dbfc7b" target="_blank" rel="external">Digital Ocean</a> in 55 seconds. Sign up using my link and receive $10.00 in free credit: <a href="https://www.digitalocean.com/?refcode=e91058dbfc7b" target="_blank" rel="external">https://www.digitalocean.com/?refcode=e91058dbfc7b</a></p>
</blockquote>
<p>– Scarlz: <a href="https://twitter.com/5car1z" target="_blank" rel="external">@5car1z</a></p>
</div><footer class="post__foot u-cf"><ul class="post__tag u-fl"><li class="post__tag__item"><a href="/tags/Git/" class="post__tag__link">Git</a></li><li class="post__tag__item"><a href="/tags/VCS/" class="post__tag__link">VCS</a></li><li class="post__tag__item"><a href="/tags/GitHub/" class="post__tag__link">GitHub</a></li></ul><a href="/2016/04/26/github-flow/#disqus_thread" class="post__foot-link u-fr">COMMENTS</a></footer></article><article class="post"><header class="post__head"><time datetime="2016-03-14T00:00:00.000Z" class="post__time">March 14, 2016</time><h1 class="post__title"><a href="/2016/03/14/docker-data-volumes/">Docker - Data Volumes and Data Containers (4)</a></h1></header><div class="post__main echo"><p><img src="http://i.imgur.com/poo8Rai.png" alt="Docker Logo"></p>
<h1 id="Preamble"><a href="#Preamble" class="headerlink" title="Preamble"></a>Preamble</h1><blockquote>
<p><strong><a href="https://docs.docker.com/engine/admin/volumes/volumes/" target="_blank" rel="external">This blog post is becoming more and more outdated as time goes on, it would be better to consult the official Docker documentation for this kind of thing!</a></strong></p>
</blockquote>
<p>Docker containers are a lot more scalable and modular once they have the links in place that allow them to share data. How these links are created and arranged depends upon the arranger, who will choose either to create a file-system data volume or a dedicated data volume container. </p>
<p>This post works through these two common choices; data volumes and data volume containers. With consideration of the commands involved in backing up, restoring, and migrating said data volumes.</p>
<p>This is post four on Docker following on from <a href="http://www.tricksofthetrades.net/2016/01/27/docker-further-administration-networking/">Docker - Daemon Administration and Networking (3)</a>. Go back and read the latter half of that post to see how to network containers together so they can properly communicate back and forth - if you need to. </p>
<a id="more"></a>
<hr>
<h1 id="1-–-Creating-Data-Volumes"><a href="#1-–-Creating-Data-Volumes" class="headerlink" title="1 – Creating Data Volumes"></a>1 – Creating Data Volumes</h1><p>A “data volume” is a marked directory inside of a container that exists to hold persistent or commonly shared data. Assigning these volumes is done when creating a new container. </p>
<p>Any data already present as part of the Docker image in a targeted volume directory is carried forward into the new container and not lost. This however is not true when mounting a local host directory (covered later) as the data is temporarily covered by the new volume. </p>
<iframe width="1080" height="500" src="https://www.youtube.com/embed/e1yXmc7-mU4" frameborder="1" allowfullscreen><br></iframe> 

<p>You can add a data volume to a container using the <code>-v</code> flag in conjunction with the <code>create</code> or <code>run</code> command. You can use the -<code>v</code> multiple times to mount multiple data volumes.</p>
<p>This next command will create a data volume inside a new container in the <code>/webapp</code> directory. </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run <span class="_">-d</span> -P --name <span class="built_in">test</span>-container -v /webapp training/webapp python app.py</span><br></pre></td></tr></table></figure>
<p>Data volumes are very useful as once designated and created they can be shared and included as part of other containers. It’s also important to note that any changes to data volumes are not included when you update an image, but conversely data volumes will persist even if the container itself is deleted.</p>
<blockquote>
<p><strong>Note:</strong> The <code>VOLUME</code> instruction in a <code>Dockerfile</code> will add one or more new volumes to any containers created from the image.</p>
</blockquote>
<p>This preservation is due to the fact that data volumes are meant to persist independent of a container’s life cycle. In turn this also means Docker never <em>garbage collects</em> volumes that are no longer in use by a container. </p>
<hr>
<h1 id="2-–-Creating-Host-Data-Volumes"><a href="#2-–-Creating-Host-Data-Volumes" class="headerlink" title="2 – Creating Host Data Volumes"></a>2 – Creating Host Data Volumes</h1><p>You can instead mount a directory from your Docker daemon’s <strong>host</strong> into a container; you may have seen this used once or twice in the previous posts. </p>
<p>Mounting a host directory can be useful for testing. For example, you can mount source code inside a container. Then, change the source code and see its effect on the application in real time. The directory on the host must be specified as an absolute path and if the directory doesn’t exist Docker will automatically create it for you. </p>
<p>The next example command mounts the host directory <code>/src/webapp</code> into the container at the <code>/opt/webapp</code> directory. </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run <span class="_">-d</span> -P --name <span class="built_in">test</span>-container -v /src/webapp:/opt/webapp training/webapp python app.py</span><br></pre></td></tr></table></figure>
<p>Some internal rules and behaviours for this process are:</p>
<ul>
<li><p>The targeted container directory must always take an absolute full file-system path.</p>
</li>
<li><p>The host source directory can be either an absolute path or a name value. </p>
</li>
<li><p>If the targeted container path already exists inside the container’s image, the host directory mount overlays but does not remove the destination content. Once the mount is removed, the destination content is accessible again. </p>
</li>
</ul>
<p>Docker volumes default to mounting as both a dual read-write mode, but you can set them to mount as read-only if you like.</p>
<p>Here the same <code>/src/webapp</code> directory is linked again but the extra <code>:ro</code> option makes the mount read-only.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run <span class="_">-d</span> -P --name web -v /src/webapp:/opt/webapp:ro training/webapp python app.py</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>Note:</strong> It’s not possible to mount a host directory using a <code>Dockerfile</code> because by convention images should be portable and flexible, and a specific host directory might not be available on all potential hosts.</p>
</blockquote>
<hr>
<h1 id="3-–-Mounting-Individual-Host-Files"><a href="#3-–-Mounting-Individual-Host-Files" class="headerlink" title="3 – Mounting Individual Host Files"></a>3 – Mounting Individual Host Files</h1><p>The <code>-v</code> flag used so far can target a single file instead of entire directories from the host machine. This is done by mapping the specific file on each side of the container. </p>
<p>A great interactive example of this that creates a new container and drops you into a bash shell with your bash history from the host, is as follows:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run --rm -it -v ~/.bash_history:/root/.bash_history ubuntu /bin/bash</span><br></pre></td></tr></table></figure>
<p>Furthermore when you exit the container, the host version of the file will have the the commands typed from the inside of the container - written to the the <code>.bash_history</code> file. </p>
<hr>
<h1 id="4-–-Creating-Dedicated-Data-Volume-Containers"><a href="#4-–-Creating-Dedicated-Data-Volume-Containers" class="headerlink" title="4 – Creating Dedicated Data Volume Containers"></a>4 – Creating Dedicated Data Volume Containers</h1><p>A popular practice with Docker data sharing is to create a dedicated container that holds all of your persistent shareable data resources, mounting the data inside of it into other containers once created and setup. </p>
<p>This example taken from the Docker documentation uses the <code>postgres</code> SQL training image as a base for the data volume container. </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker create -v /data-store --name data-store training/postgres /bin/<span class="literal">true</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>Note:</strong> <code>/bin/true</code> - returns a <code>0</code> and does nothing if the command was successful. </p>
</blockquote>
<p>The <code>--volumes-from</code> flag is then used to mount the <code>/data-store</code> volume inside of other containers:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run <span class="_">-d</span> --volumes-from data-store --name database-container-1 training/postgres</span><br></pre></td></tr></table></figure>
<p>This process is repeated for additional new containers:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run <span class="_">-d</span> --volumes-from data-store --name database-container-2  training/postgres</span><br></pre></td></tr></table></figure>
<p>Be aware that you can use multiple <code>--volumes-from</code> flags in one command to combine data volumes from multiple other dedicated data containers. </p>
<p>An alternative idea is to mount the volumes from each subsequent container to the next, instead of the original dedicated container linking to new ones. </p>
<p>This forms a chain that would begin by using: </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run <span class="_">-d</span> --name database-container-3 --volumes-from database-container-2  training/postgres</span><br></pre></td></tr></table></figure>
<p>Remember that If you remove containers that mount volumes, the volume store and its data will not be deleted. Docker preserves it. </p>
<p>To fully delete a volume from the file-system you must run:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker rm -v &lt;container name&gt;</span><br></pre></td></tr></table></figure>
<p>Where <code>&lt;container name&gt;</code> is “the last container with a reference to the volume.”</p>
<blockquote>
<p><strong>Note:</strong> There is no cautionary Docker warning provided when removing a container without  the <code>-v</code> option.  So if a container has volumes mounted the <code>-v</code> must be passed to fully remov them. </p>
</blockquote>
<h2 id="Dangling-Volumes"><a href="#Dangling-Volumes" class="headerlink" title="Dangling Volumes"></a>Dangling Volumes</h2><p>“Dangling volumes” refers to container volumes that are no longer referenced by a container.</p>
<p>Fortunately there is a command to list out all the stray volumes on a system.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker volume ls <span class="_">-f</span> dangling=<span class="literal">true</span></span><br></pre></td></tr></table></figure>
<p>To remove a volume that’s no longer needed use:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker volume rm &lt;volume name&gt;</span><br></pre></td></tr></table></figure>
<p>Where <code>&lt;volume name&gt;</code> is substituted for the dangling volume name shown in the previous <code>ls</code> output. </p>
<hr>
<h1 id="5-–-Backing-Up-and-Restoring-Data-Volumes"><a href="#5-–-Backing-Up-and-Restoring-Data-Volumes" class="headerlink" title="5 – Backing Up and Restoring Data Volumes"></a>5 – Backing Up and Restoring Data Volumes</h1><p>How are data volumes maintained when it comes to things like backups, restoration, and migration? Well here is one solution that takes care of these necessities by showing how you can achieve this with a dedicated data container. </p>
<p>To backup a volume:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run --rm --volumes-from data-container -v $(<span class="built_in">pwd</span>):/backup ubuntu tar cvf /backup/backup.tar /data-store</span><br></pre></td></tr></table></figure>
<p>Here’s how the previous command works:</p>
<ol>
<li>The <code>--volumes-from</code> flag creates a new nameless container that mounts the data volume inside <code>data-container</code> you wish to backup. </li>
<li>A localhost directory is mounted as <code>/backup</code> . Then <code>tar</code> archives the contents of the <code>/data-store</code> volume to a <code>backup.tar</code> file inside the local <code>/backup</code> directory. </li>
<li>The container will be <code>--rm</code> removed once it eventually ends and exits. </li>
</ol>
<p>We are left with a backup of the <code>/data-store</code> volume on the localhost. </p>
<p>From here you could restore the volume in whatever way you wish.</p>
<p>To restore into a new container run: </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -v /data-store --name data-container-2 ubuntu /bin/bash</span><br></pre></td></tr></table></figure>
<p>Then extract the backup file contents into the the new container’s data volume:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run --rm --volumes-from data-container-2 -v $(<span class="built_in">pwd</span>):/backup ubuntu bash -c <span class="string">"cd /data-store &amp;&amp; tar -xvf /backup/backup.tar"</span></span><br></pre></td></tr></table></figure>
<p>Now the new container is up and running with the files from the original <code>/data-store</code> volume. </p>
<hr>
<h1 id="6-–-Volume-and-Data-Container-Issues"><a href="#6-–-Volume-and-Data-Container-Issues" class="headerlink" title="6 – Volume and Data Container Issues"></a>6 – Volume and Data Container Issues</h1><ul>
<li><p><strong>Orphan Volumes</strong> – Referred to as dangling volumes earlier on. These are the leftover untracked volumes that aren’t removed from the system once a container is removed/deleted. </p>
</li>
<li><p><strong>Security</strong> – Other than the usual Unix file permissions and the ability to set read-only or read-write privileges. Docker volumes or data containers have no additional security placed on them. </p>
</li>
<li><p><strong>Data Integrity</strong> – Sharing data using volumes and data containers provides no level of data integrity protection. Data protection features are not yet built into Docker i.e. data snapshot, automatic data replication, automatic backups, etc. So data management has to be handled by the administrator or the container itself. </p>
</li>
<li><p><strong>External Storage</strong> –  The current design does not take into account the ability to use a Docker volume spanning from one host to another. They must be on the same host. </p>
</li>
</ul>
<hr>
<p>It seems like a large amount of information has been covered here but really only two ideas have been explored. That of singular data volumes and that of the preferred independent data container. There are also new updates to Docker on the horizon as always so some of the issues raised here are hopefully soon to be resolved. The next post on Docker covers building images using Dockerfiles, and likewise with Docker Compose. </p>
<p><a href="http://www.tricksofthetrades.net/trades/">Links to subsequent Docker posts can be found on the Trades page.</a></p>
<p><strong>More Information</strong></p>
<ul>
<li><a href="https://docs.docker.com/engine/userguide/dockervolumes/" target="_blank" rel="external">Official Docker Documentation – Manage Data in Containers</a> – Main source material used for this post. </li>
<li><a href="https://www.digitalocean.com/community/tutorials/how-to-work-with-docker-data-volumes-on-ubuntu-14-04" target="_blank" rel="external">Digital Ocean - How To Work with Docker Data Volumes on Ubuntu 14.04</a> – Breaks down the topic further and has some Nginx logging volume mount examples. </li>
<li><a href="http://www.computerweekly.com/feature/Docker-storage-101-How-storage-works-in-Docker" target="_blank" rel="external">Docker storage 101: How storage works in Docker</a> – Article from April 2015 that goes over the general ideas and practices discussed here. </li>
</ul>
<blockquote>
<p>Easily deploy an SSD cloud server on <a href="https://www.digitalocean.com/?refcode=e91058dbfc7b" target="_blank" rel="external">Digital Ocean</a> in 55 seconds. Sign up using my link and receive $10.00 in free credit: <a href="https://www.digitalocean.com/?refcode=e91058dbfc7b" target="_blank" rel="external">https://www.digitalocean.com/?refcode=e91058dbfc7b</a></p>
</blockquote>
<p>– Scarlz: <a href="https://twitter.com/5car1z" target="_blank" rel="external">@5car1z</a></p>
</div><footer class="post__foot u-cf"><ul class="post__tag u-fl"><li class="post__tag__item"><a href="/tags/Docker/" class="post__tag__link">Docker</a></li><li class="post__tag__item"><a href="/tags/Containers/" class="post__tag__link">Containers</a></li><li class="post__tag__item"><a href="/tags/Virtualisation/" class="post__tag__link">Virtualisation</a></li></ul><a href="/2016/03/14/docker-data-volumes/#disqus_thread" class="post__foot-link u-fr">COMMENTS</a></footer></article><article class="post"><header class="post__head"><time datetime="2016-02-24T00:00:00.000Z" class="post__time">February 24, 2016</time><h1 class="post__title"><a href="/2016/02/24/bowtie-static-site-service/">BowTie Static Web Hosting Service</a></h1></header><div class="post__main echo"><p><img src="http://i.imgur.com/ZIQzKNY.png" alt="BowTie Banner Image"></p>
<h1 id="Preamble"><a href="#Preamble" class="headerlink" title="Preamble"></a>Preamble</h1><p>Static sites continue to surge in popularity and show no sign of falling out of favour anytime soon. It’s only natural then that content management platforms centered around static websites make an appearance. Thus comes BowTie!</p>
<p><a href="https://bowtie.io/" target="_blank" rel="external">https://bowtie.io/</a></p>
<blockquote>
<p><strong>“BowTie is an enhanced static hosting environment that lets you deploy feature-rich static sites and applications without needing to build the same services over and over.”</strong></p>
</blockquote>
<p>In this post I’ll go through the bare-bones project creation after registering with the service. This will be just enough to get you introduced to BowTie and comes from the context of a client machine running Linux. </p>
<a id="more"></a>
<hr>
<h1 id="1-–-Introduction"><a href="#1-–-Introduction" class="headerlink" title="1 – Introduction"></a>1 – Introduction</h1><p>BowTie caters primarily to the technical users out there who host and run their own static sites as it gives free reign over the code and source files for all of its projects. That being said it’s very simple to get started with and beginners or newer users interested in static site development have a great tool at their disposal to begin learning from. </p>
<p>It also has the utility provided to hand over the control of a site and its contents to non-developers or everyday end-users, in the same way a CMS/Wordpress platform would.  </p>
<p>To deliver this service and solution BowTie provides private Git repos, domain and SSL configuration, policy controls, Stripe payment/subscription support, and the tried and tested Jekyll platform for all of its content generation. </p>
<hr>
<h1 id="2-–-Sign-Up"><a href="#2-–-Sign-Up" class="headerlink" title="2 – Sign Up"></a>2 – Sign Up</h1><p>Free trials are available to anyone interested. </p>
<p>Simply sign up to the BowTie service at the below link to begin your free trial: </p>
<blockquote>
<p><a href="https://bowtie.io/owners/sign_up" target="_blank" rel="external">https://bowtie.io/owners/sign_up</a></p>
</blockquote>
<p>The SSO (Single Sign On) option for authentication with a GitHub account is even quicker and gives the service a gateway to your assets there.  </p>
<p><img src="http://i.imgur.com/oTwBYGf.png" alt="BowTie Signup Form Image"></p>
<hr>
<h1 id="3-–-Project-Name-and-Template"><a href="#3-–-Project-Name-and-Template" class="headerlink" title="3 – Project Name and Template"></a>3 – Project Name and Template</h1><p>Once registered and logged in it’s time to create your first BowTie project.</p>
<p>Give the project a suitable name - this can be the domain name you want to use for hosting when you add the appropriate extension to the entry. Like in my example (pictured) a new domain for the name is not mandatory however.  </p>
<p><img src="http://i.imgur.com/vapa4aV.png" alt="Project Name Image"></p>
<p>The second selection is the type of template you want to use for this site/project and mainly dictates your starting site layout, components, and functionality you begin with. </p>
<p>There are quite a few options here to choose from, and the choice will depend upon your own needs and requirements. </p>
<p>For example purposes and simplicitys sake I’m selecting the “just a blog” option.</p>
<p><img src="http://i.imgur.com/8dUYPPE.png" alt="Template Selection Image"></p>
<hr>
<h1 id="4-–-Roll-Out-and-Dashboard"><a href="#4-–-Roll-Out-and-Dashboard" class="headerlink" title="4 – Roll Out and Dashboard"></a>4 – Roll Out and Dashboard</h1><p>After confirming the previous choice BowTie takes several minutes to generate and setup the project. Patience is key here but it doesn’t take too much time overall. </p>
<p><img src="http://i.imgur.com/36WseTX.png" alt="Progress Bars Image"></p>
<p>Click the green “Roll Out” button to launch the project dashboard:</p>
<p><img src="http://i.imgur.com/V9C4Vrp.png" alt="Project Dashboard Image"></p>
<hr>
<h1 id="5-–-Add-Public-SSH-Key-to-BowTie"><a href="#5-–-Add-Public-SSH-Key-to-BowTie" class="headerlink" title="5 – Add Public SSH Key to BowTie"></a>5 – Add Public SSH Key to BowTie</h1><p>From within the dashboard menus and sub-menus, locate the SSH key section pictured in the next screenshot.</p>
<p><img src="http://i.imgur.com/1NOVzKM.png" alt="Public Keys Form"></p>
<p>If you can’t find the page, use the URL below whilst logged in to BowTie to be taken to it. </p>
<blockquote>
<p><a href="https://bowtie.io/keys/new" target="_blank" rel="external">https://bowtie.io/keys/new</a></p>
</blockquote>
<p>Next locate your client machine’s public SSH key and copy the contents into the form on this “Keys” page. </p>
<p>On Linux systems SSH keys stored in <code>~/.ssh/</code> are easily copied to the system clipboard using xclip.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ xclip -selection c -i ~/.ssh/id_rsa.pub</span><br></pre></td></tr></table></figure>
<p>If you don’t have an SSH key you can generate one using the <code>ssh-keygen</code> program:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ssh-keygen -t rsa -b 4096</span><br></pre></td></tr></table></figure>
<hr>
<h1 id="6-–-Install-the-BowTie-Client"><a href="#6-–-Install-the-BowTie-Client" class="headerlink" title="6 – Install the BowTie Client"></a>6 – Install the BowTie Client</h1><p>Have Ruby (at least version 2.0) installed on your system. This is required for running and installing BowTie.</p>
<p>Details on how to install Ruby are located in full here:</p>
<blockquote>
<p><a href="https://www.ruby-lang.org/en/documentation/installation/" target="_blank" rel="external">https://www.ruby-lang.org/en/documentation/installation/</a></p>
</blockquote>
<p>Once Ruby is installed issue the command:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ gem install bowtie-io</span><br></pre></td></tr></table></figure>
<p>This installs the BowTie client we need. </p>
<hr>
<h1 id="7-–-Clone-Your-Project’s-Git-Repository"><a href="#7-–-Clone-Your-Project’s-Git-Repository" class="headerlink" title="7 – Clone Your Project’s Git Repository"></a>7 – Clone Your Project’s Git Repository</h1><p>With your Git SSH clone URL - which is found on the BowTie website project dashboard and looks similar to this:</p>
<p><img src="http://i.imgur.com/sFpmQcz.png" alt="BowTie Git Clone URL Image"></p>
<p>Clone the project’s Git repository onto your local file-system.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git <span class="built_in">clone</span> git@git.bowtie.io:tricksofthetrades.git</span><br></pre></td></tr></table></figure>
<p>Remember this example is for my own project. You must substitute in <strong>your</strong> repo address from the BowTie dashboard when using the previous command. </p>
<hr>
<h1 id="8-–-Run-the-BowTie-Test-Server"><a href="#8-–-Run-the-BowTie-Test-Server" class="headerlink" title="8 – Run the BowTie Test Server"></a>8 – Run the BowTie Test Server</h1><p>Change the current working directory to the cloned repository from the previous step (yours will be named differently).</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> tricksofthetrades</span><br></pre></td></tr></table></figure>
<p>Run the BowTie test server to generate and host the static HTML content.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bowtie serve</span><br></pre></td></tr></table></figure>
<p>If the build process succeeds a variation of the following output is returned:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Configuration file: /home/scarlz/tricksofthetrades/_config.yml</span><br><span class="line">            Source: /home/scarlz/tricksofthetrades</span><br><span class="line">       Destination: /home/scarlz/tricksofthetrades/_site</span><br><span class="line"> Incremental build: disabled. Enable with --incremental</span><br><span class="line">      Generating... </span><br><span class="line">                    <span class="keyword">done</span> <span class="keyword">in</span> 1.103 seconds.</span><br><span class="line"> Auto-regeneration: enabled <span class="keyword">for</span> <span class="string">'/home/scarlz/tricksofthetrades'</span></span><br><span class="line">Configuration file: /home/scarlz/tricksofthetrades/_config.yml</span><br><span class="line">Configuration file: /home/scarlz/tricksofthetrades/_config.yml</span><br><span class="line">[2016-02-22 17:58:51] INFO  WEBrick 1.3.1</span><br><span class="line">[2016-02-22 17:58:51] INFO  ruby 2.3.0 (2015-12-25) [i686-linux]</span><br><span class="line">[2016-02-22 17:58:51] INFO  WEBrick::HTTPServer<span class="comment">#start: pid=7149 port=4000</span></span><br></pre></td></tr></table></figure>
<p>In the event that the build process fails - any extra Jekyll gems you might need to successfully build and run the project are highlighted as dependencies in the error message. </p>
<p>These dependencies are installed simply by using the name of the gem with the Ruby command from earlier. </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ gem install &lt;dependency-name&gt;</span><br></pre></td></tr></table></figure>
<p>After the server runs successfully; visit the address below on your client machine’s web browser.  </p>
<blockquote>
<p><a href="http://localhost:4000/" target="_blank" rel="external">http://localhost:4000/</a></p>
</blockquote>
<p>You should at this address see the BowTie static webpages for the template style you chose at the beginning!</p>
<p><img src="http://i.imgur.com/Dy2bqdd.png" alt="Blog Template Page Image"></p>
<hr>
<h1 id="9-–-Read-the-Docs"><a href="#9-–-Read-the-Docs" class="headerlink" title="9 – Read the Docs"></a>9 – Read the Docs</h1><p>From here on out as a developer you’ll of course want to customise the site files in the local Git repo, and commit then push the changes. For those who aren’t sure what to do next take a look at the project dashboard again as well as some of the documentation in this step of the post.</p>
<p>It’s also from the project dashboard you can gain access to the live site hosted through BowTie. </p>
<p><img src="http://i.imgur.com/WV2hizc.png" alt="BowTie Live Project Button"></p>
<p>All in all the instructions in this post are pretty brief. To read a much more thorough walkthrough of this process consult the official post:</p>
<ul>
<li><a href="https://bowtie.io/help/getting-started-with-bowtie/" target="_blank" rel="external">https://bowtie.io/help/getting-started-with-bowtie/</a></li>
</ul>
<p>As mentioned the next step is to learn how to customise, refine, and re-design the site templates. So check this out:</p>
<ul>
<li><a href="https://bowtie.io/help/style-customize-bowtie-frontend/" target="_blank" rel="external">https://bowtie.io/help/style-customize-bowtie-frontend/</a></li>
</ul>
<p>Furthermore refer to these individual guides that show how to add content to the different types of projects on offer:</p>
<ul>
<li><a href="https://bowtie.io/examples/" target="_blank" rel="external">https://bowtie.io/examples/</a></li>
</ul>
<p>And for any other concerns look into the general BowTie documentation hosted at:</p>
<ul>
<li><a href="https://bowtie.io/docs/#what-is-8904-bowtie" target="_blank" rel="external">https://bowtie.io/docs/#what-is-8904-bowtie</a></li>
</ul>
<hr>
<p>The free trial lasts 14 days in total with the lowest tier payment plan currently costing a very cheap $5.00 a month; allowing one hosted project and access to all of the BowTie services.</p>
<p>The subsequent and higher tier pricing plans on offer are explained here:</p>
<blockquote>
<p><a href="https://bowtie.io/pricing/" target="_blank" rel="external">https://bowtie.io/pricing/</a></p>
</blockquote>
<p>Have fun designing and hosting your static sites! </p>
<p><strong>More Information</strong></p>
<ul>
<li><a href="https://bowtie.io/support/" target="_blank" rel="external">BowTie’s Support Page</a> – Has FAQ’s and links to the Docs plus a Slack support channel link. </li>
<li><a href="https://bowtie.io/blog/" target="_blank" rel="external">BowTie’s Official Blog</a> – BowTie’s official news blog. </li>
<li><a href="https://github.com/bowtie-io/bowtie-io" target="_blank" rel="external">BowTie.io on GitHub</a> – Source for the Ruby client downloaded and organisation page.</li>
</ul>
<blockquote>
<p>Easily deploy an SSD cloud server on <a href="https://www.digitalocean.com/?refcode=e91058dbfc7b" target="_blank" rel="external">Digital Ocean</a> in 55 seconds. Sign up using my link and receive $10.00 in free credit: <a href="https://www.digitalocean.com/?refcode=e91058dbfc7b" target="_blank" rel="external">https://www.digitalocean.com/?refcode=e91058dbfc7b</a></p>
</blockquote>
<p>– Scarlz: <a href="https://twitter.com/5car1z" target="_blank" rel="external">@5car1z</a></p>
</div><footer class="post__foot u-cf"><ul class="post__tag u-fl"><li class="post__tag__item"><a href="/tags/HTML/" class="post__tag__link">HTML</a></li><li class="post__tag__item"><a href="/tags/Static/" class="post__tag__link">Static</a></li><li class="post__tag__item"><a href="/tags/Jekyll/" class="post__tag__link">Jekyll</a></li></ul><a href="/2016/02/24/bowtie-static-site-service/#disqus_thread" class="post__foot-link u-fr">COMMENTS</a></footer></article><article class="post"><header class="post__head"><time datetime="2016-02-10T00:00:00.000Z" class="post__time">February 10, 2016</time><h1 class="post__title"><a href="/2016/02/10/ansible-installing-running/">Ansible - Installing and Running (1)</a></h1></header><div class="post__main echo"><p><img src="http://i.imgur.com/9HBs9cy.png" alt="Ansible Logo"></p>
<h1 id="Preamble"><a href="#Preamble" class="headerlink" title="Preamble"></a>Preamble</h1><p>Ansible is one of many configuration management tools but has its own unique set of differences. The platform aims to provide solutions for the entirety of a setup. With consideration for infrastructure provisioning, application deployment, and overall orchestration taken into account.  </p>
<p>Some of its features it uses to achieve this are agentless management, multi-node deployment, ad hoc task execution, module libraries, and use of higher level install scripts referred to as <em>playbooks</em>. Security and reliability is maintained throughout this with SSH as the transport protocol.  </p>
<p>Compared to to other CM tools the learning curve is also seen as much lower with Ansible, making it easier to understand and use from the outset. Only Python and a designated control machine are required for the actual installation. With all configuration for the “inventory” assets written in YAML to keep things simple and clean. </p>
<blockquote>
<p><a href="http://www.ansible.com/" target="_blank" rel="external">http://www.ansible.com/</a></p>
</blockquote>
<a id="more"></a>
<hr>
<h1 id="1-–-Control-Machine-Installation"><a href="#1-–-Control-Machine-Installation" class="headerlink" title="1 – Control Machine Installation"></a>1 – Control Machine Installation</h1><p>The host you want to use as the <em>control machine</em> for Ansible requires Python 2.6 or 2.7 installed. This control machine can be a desktop, laptop, or workstation etc as long it’s running a Linux based OS such as Debian/Ubuntu, Arch, CentOS, RHEL, OS X, or any version of BSD. </p>
<p>Windows as a platform is not currently supported for the control machine. </p>
<p>In this post the commands are shown for installing Ansible onto the control machine using system package managers, and for only a few of the many Linux distributions on offer.</p>
<h2 id="Arch-Linux"><a href="#Arch-Linux" class="headerlink" title="Arch Linux"></a>Arch Linux</h2><p><a href="https://wiki.archlinux.org/index.php/Ansible" target="_blank" rel="external">Ansible</a> has a Pacman package in the community repository.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo pacman -S ansible</span><br></pre></td></tr></table></figure>
<p>The AUR also has a package build that pulls directly from GitHub called <code>ansible-git</code>. Any Aurum helper can be used to automatically build and install this, for example:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ yaourt -S ansible-git</span><br></pre></td></tr></table></figure>
<h2 id="Debian"><a href="#Debian" class="headerlink" title="Debian"></a>Debian</h2><p>Open up the Debian software sources file.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo vim /etc/apt/sources.list</span><br></pre></td></tr></table></figure>
<p>Add the following line to <code>/etc/apt/sources.list</code>:</p>
<p><code>deb http://ppa.launchpad.net/ansible/ansible/ubuntu trusty main</code></p>
<p>Add the Ansible software repository key to the system; it’s the same source as the Ubuntu PPA. </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 93C4A3FD7BB9C367</span><br></pre></td></tr></table></figure>
<p>Update the package manager to verify the changes and then install Ansible itself:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get update</span><br><span class="line">$ sudo apt-get install ansible</span><br></pre></td></tr></table></figure>
<h2 id="Ubuntu"><a href="#Ubuntu" class="headerlink" title="Ubuntu"></a>Ubuntu</h2><p>Install the common software properties package if you don’t already have it. </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install software-properties-common</span><br></pre></td></tr></table></figure>
<p>Add the official Ansible package repository to the system and update the package manager database. </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-add-repository ppa:ansible/ansible</span><br><span class="line">$ sudo apt-get update</span><br></pre></td></tr></table></figure>
<p>Install Ansible from the newly added package repository.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install ansible</span><br></pre></td></tr></table></figure>
<h2 id="Fedora"><a href="#Fedora" class="headerlink" title="Fedora"></a>Fedora</h2><p>Fedora users can install Ansible directly:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo yum -y update</span><br><span class="line">$ sudo yum -y install ansible</span><br></pre></td></tr></table></figure>
<h2 id="RHEL-CentOS"><a href="#RHEL-CentOS" class="headerlink" title="RHEL / CentOS"></a>RHEL / CentOS</h2><p><a href="http://fedoraproject.org/wiki/EPEL" target="_blank" rel="external">EPEL must be configured before trying to install Ansible on these systems.</a> </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo yum -y update</span><br><span class="line">$ sudo yum -y install ansible</span><br></pre></td></tr></table></figure>
<hr>
<h1 id="2-–-Remote-Nodes-SSH-Setup"><a href="#2-–-Remote-Nodes-SSH-Setup" class="headerlink" title="2 – Remote Nodes SSH Setup"></a>2 – Remote Nodes SSH Setup</h1><p>On the remote nodes you want Ansible to interact with you need to register the control machine’s public SSH key. This is as Ansible uses SSH to communicate and operate by default. </p>
<p>To generate a new SSH key for the control machine use the next command on the control machine host:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> .ssh/ </span><br><span class="line">$ ssh-keygen -t rsa -b 4096 -C <span class="string">"ansible-control-host"</span></span><br></pre></td></tr></table></figure>
<p>Then copy the new key across to the remote client nodes; changing the <code>-p</code> value for your own relevant SSH port number. Along with the usernames plus remote host IP addresses. </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ ssh-copy-id -i ansible-control-host -p 3980 username@remote.one.ip.address</span><br><span class="line">$ ssh-copy-id -i ansible-control-host -p 3980 username@remote.two.ip.address</span><br><span class="line">$ ssh-copy-id -i ansible-control-host -p 3980 username@remote.three.ip.address</span><br></pre></td></tr></table></figure>
<p>Next open the main Ansible configuration file; which is explained more in a latter section. </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/ansible/ansible.cfg</span><br></pre></td></tr></table></figure>
<p>Locate the lines that describe private key authentication (shown below) and remove the <code>#</code> symbol whilst adding in the path to the new private key we created.</p>
<figure class="highlight bash"><figcaption><span>/etc/ansible/ansible.cfg</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># if set, always use this private key file for authentication, same as</span></span><br><span class="line"><span class="comment"># if passing --private-key to ansible or ansible-playbook</span></span><br><span class="line">private_key_file = ~/.ssh/ansible-control-host</span><br></pre></td></tr></table></figure>
<p>Save and exit the file. </p>
<p>This forces Ansible to use this private key for all operations by default. An alternative to this would be to use the <code>ansible_ssh_private_key_file</code> variable in the <code>hosts</code> file explained later on. </p>
<p>Like with the control machine the remote nodes must have Python installed (2.4 or later) as a prerequisite to using Ansible with them. So any remote nodes that do not have Python already installed must be attended to before continuing. </p>
<hr>
<h1 id="3-–-Ansible-Hosts-File-Setup"><a href="#3-–-Ansible-Hosts-File-Setup" class="headerlink" title="3 – Ansible Hosts File Setup"></a>3 – Ansible Hosts File Setup</h1><iframe width="1080" height="500" src="https://www.youtube.com/embed/xew7CMkL7jY" frameborder="1" allowfullscreen><br></iframe>

<p>Continuing on with the control machine - backup the template Ansible hosts file.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo mv /etc/ansible/hosts /etc/ansible/hosts.orig</span><br></pre></td></tr></table></figure>
<p>Begin writing to a new buffer to create a new “hosts” file.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo vim /etc/ansible/hosts</span><br></pre></td></tr></table></figure>
<p>Add the contents of the next code snippet into the hosts file, substituting in the IP addresses of your remotes in the process.</p>
<figure class="highlight yaml"><figcaption><span>/etc/ansible/hosts</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">[servers]</span></span><br><span class="line"><span class="string">remote.one.ip.address</span></span><br><span class="line"><span class="string">remote.two.ip.address</span></span><br><span class="line"><span class="string">remote.three.ip.address</span></span><br></pre></td></tr></table></figure>
<p>This configuration file is very flexible and can be expanded to use variables, aliases, and port numbers. Which is what we need to add to ensure the SSH connectivity. </p>
<blockquote>
<p><strong>Note:</strong> If your SSH port is the default port 22 on these remote nodes then you do not have to set this upcoming port variable.</p>
</blockquote>
<p>Expand the file by adding a hostname alias, host variable, user variable, and port number variable:</p>
<figure class="highlight yaml"><figcaption><span>/etc/ansible/hosts</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">[servers]</span></span><br><span class="line"><span class="string">server-name-1</span> <span class="string">ansible_host=remote.one.ip.address</span> <span class="string">ansible_user=username</span> <span class="string">ansible_port=3980</span> </span><br><span class="line"><span class="string">server-name-2</span> <span class="string">ansible_host=remote.two.ip.address</span> <span class="string">ansible_user=username</span> <span class="string">ansible_port=3980</span> </span><br><span class="line"><span class="string">server-name-3</span> <span class="string">ansible_host=remote.three.ip.address</span> <span class="string">ansible_user=username</span> <span class="string">ansible_port=3980</span></span><br></pre></td></tr></table></figure>
<p>Save the changes and exit the text editor. </p>
<p>As an extra option here, adding an <code>ansible_ssh_private_key_file=~/.ssh/ansible-control-host</code> variable to each host line is another possibility. Instead of what we set in the last step i.e. the default private key directive in Ansible’s main configuration file (<code>ansible.cfg</code>). </p>
<hr>
<h1 id="4-–-Test-Ansible-Connectivity"><a href="#4-–-Test-Ansible-Connectivity" class="headerlink" title="4 – Test Ansible Connectivity"></a>4 – Test Ansible Connectivity</h1><p>An Ansible module named “ping” is useful for testing the previous host file configuration we added.</p>
<p>Note that <code>all</code> can be replaced for a group name like <code>server</code> - which is taken from the example earlier to only select those hosts in that group. </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ansible all -m ping</span><br></pre></td></tr></table></figure>
<p>A successful hosts and SSH key configuration returns an output similar to:</p>
<figure class="highlight bash"><figcaption><span>Output</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">hostname1 | SUCCESS =&gt; &#123;</span><br><span class="line">    <span class="string">"changed"</span>: <span class="literal">false</span>, </span><br><span class="line">    <span class="string">"invocation"</span>: &#123;</span><br><span class="line">        <span class="string">"module_args"</span>: &#123;</span><br><span class="line">            <span class="string">"data"</span>: null</span><br><span class="line">        &#125;, </span><br><span class="line">        <span class="string">"module_name"</span>: <span class="string">"ping"</span></span><br><span class="line">    &#125;, </span><br><span class="line">    <span class="string">"ping"</span>: <span class="string">"pong"</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">hostname2 | SUCCESS =&gt; &#123;</span><br><span class="line">    <span class="string">"changed"</span>: <span class="literal">false</span>, </span><br><span class="line">    <span class="string">"invocation"</span>: &#123;</span><br><span class="line">        <span class="string">"module_args"</span>: &#123;</span><br><span class="line">            <span class="string">"data"</span>: null</span><br><span class="line">        &#125;, </span><br><span class="line">        <span class="string">"module_name"</span>: <span class="string">"ping"</span></span><br><span class="line">    &#125;, </span><br><span class="line">    <span class="string">"ping"</span>: <span class="string">"pong"</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">hostname3 | SUCCESS =&gt; &#123;</span><br><span class="line">    <span class="string">"changed"</span>: <span class="literal">false</span>, </span><br><span class="line">    <span class="string">"invocation"</span>: &#123;</span><br><span class="line">        <span class="string">"module_args"</span>: &#123;</span><br><span class="line">            <span class="string">"data"</span>: null</span><br><span class="line">        &#125;, </span><br><span class="line">        <span class="string">"module_name"</span>: <span class="string">"ping"</span></span><br><span class="line">    &#125;, </span><br><span class="line">    <span class="string">"ping"</span>: <span class="string">"pong"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Manual options are also sometimes added to these <em>ad hoc</em> Ansible commands. </p>
<p>Here <code>-u</code> selects a Linux user to issue the command as: </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ansible all -m ping -u &lt;username&gt;</span><br></pre></td></tr></table></figure>
<p>Furthermore the  <code>-b</code> option triggers the command to be run with <code>sudo</code> privileges: </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ansible all -m ping -u &lt;username&gt; -b</span><br></pre></td></tr></table></figure>
<p>This is all with the “ping” module example, but live commands are just as easy.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ansible all <span class="_">-a</span> <span class="string">"/bin/echo hello world!"</span></span><br></pre></td></tr></table></figure>
<p>You can do this without invoking the program directly and use the <code>command</code> module with Ansible instead.</p>
<p>Return the “servers” group drive partitions using the <code>df</code> program: </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ansible -m <span class="built_in">command</span> <span class="_">-a</span> <span class="string">"df -h"</span> servers</span><br></pre></td></tr></table></figure>
<p>Example output from one host:</p>
<figure class="highlight bash"><figcaption><span>Output</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">hostname1 | SUCCESS | rc=0 &gt;&gt;</span><br><span class="line">Filesystem                 Size  Used Avail Use% Mounted on</span><br><span class="line">/dev/disk/by-label/DOROOT   30G  6.1G   22G  22% /</span><br><span class="line">udev                        10M     0   10M   0% /dev</span><br><span class="line">tmpfs                      202M   25M  178M  13% /run</span><br><span class="line">tmpfs                      505M     0  505M   0% /dev/shm</span><br><span class="line">tmpfs                      5.0M     0  5.0M   0% /run/lock</span><br><span class="line">tmpfs                      505M     0  505M   0% /sys/fs/cgroup</span><br><span class="line">tmpfs                      101M     0  101M   0% /run/user/1001</span><br></pre></td></tr></table></figure>
<p>Checking disk space on multiple nodes has never been easier!</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ansible -m <span class="built_in">command</span> <span class="_">-a</span> <span class="string">"free -h"</span> servers</span><br></pre></td></tr></table></figure>
<p>Example output from one host:</p>
<figure class="highlight bash"><figcaption><span>Output</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hostname2 | SUCCESS | rc=0 &gt;&gt;</span><br><span class="line">             total       used       free     shared    buffers     cached</span><br><span class="line">Mem:          1.0G       875M       134M        25M       187M       570M</span><br><span class="line">-/+ buffers/cache:       117M       892M</span><br><span class="line">Swap:         2.0G        32K       2.0G</span><br></pre></td></tr></table></figure>
<p>Query the system’s uptime of only one requested host using the assigned alias from the hosts file:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ansible -m <span class="built_in">command</span> <span class="_">-a</span> <span class="string">"uptime -p"</span> hostname3</span><br></pre></td></tr></table></figure>
<p>Example output:</p>
<figure class="highlight bash"><figcaption><span>Output</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hostname3 | SUCCESS | rc=0 &gt;&gt;</span><br><span class="line">up 7 weeks, 1 day, 7 minutes</span><br></pre></td></tr></table></figure>
<hr>
<h1 id="5-–-Ansible-Configuration-File"><a href="#5-–-Ansible-Configuration-File" class="headerlink" title="5 – Ansible Configuration File"></a>5 – Ansible Configuration File</h1><p>Custom changes to the Ansible install and how it behaves are made through the configuration files. </p>
<p>Changes in relation to configuration are processed and picked up in the the following order:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">* ANSIBLE_CONFIG (an environment variable)</span><br><span class="line">* ansible.cfg (<span class="keyword">in</span> the current directory)</span><br><span class="line">* .ansible.cfg (<span class="keyword">in</span> the home directory)</span><br><span class="line">* .ansible.cdg (<span class="keyword">in</span> /etc/ansible/ansible.cfg)</span><br></pre></td></tr></table></figure>
<p>In this section we’re taking a quick look at the <code>ansible.cfg</code> file we modified slightly earlier. </p>
<p>There’s not much wrong with the default contents of the main <code>/etc/ansible.cfg</code> file, but you may need to delve into it at some point in the future. </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/ansible/ansible.cfg</span><br></pre></td></tr></table></figure>
<p>Here are some cherry picked lines and directives from the file that may be of interest. Remember if/when setting these to remove the <code>#</code> symbol to uncomment. </p>
<p>To assign a different directory for a custom hosts file location. </p>
<figure class="highlight bash"><figcaption><span>/etc/ansible/ansible.cfg</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#inventory = /etc/ansible/hosts</span></span><br></pre></td></tr></table></figure>
<p>This next line designates the number of parallel processes to generate when talking with remote hosts. The value will always depend upon your hardware capabilities and amount of remote nodes in play. </p>
<p>Higher fork values will help to complete actions across the nodes faster. Assuming you have the hardware needed. A common value is 50, rather than the default of 5. </p>
<figure class="highlight bash"><figcaption><span>/etc/ansible/ansible.cfg</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#forks = 5</span></span><br></pre></td></tr></table></figure>
<p>To control whether an Ansible playbook prompts for a sudo password when sudoing - set this next directive to true. </p>
<figure class="highlight bash"><figcaption><span>/etc/ansible/ansible.cfg</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#ask_sudo_pass = True</span></span><br></pre></td></tr></table></figure>
<p>Similarly to set whether an Ansible playbook prompts for a password when run - set this next line to true.</p>
<figure class="highlight bash"><figcaption><span>/etc/ansible/ansible.cfg</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#ask_pass = True</span></span><br></pre></td></tr></table></figure>
<p>This sets the default SSH port for all system connections, be aware that any settings in the inventory (e.g. hosts file) will override this. </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#remote_port = 22</span><br></pre></td></tr></table></figure>
<p>Set the time out value for SSH queries here on this line:</p>
<figure class="highlight bash"><figcaption><span>/etc/ansible/ansible.cfg</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SSH timeout</span></span><br><span class="line"><span class="comment">#timeout = 10</span></span><br></pre></td></tr></table></figure>
<p>Enable playbook logging capability in the specified directory on these lines here: </p>
<figure class="highlight bash"><figcaption><span>/etc/ansible/ansible.cfg</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># logging is off by default unless this path is defined</span></span><br><span class="line"><span class="comment"># if so defined, consider logrotate</span></span><br><span class="line"><span class="comment">#log_path = /var/log/ansible.log</span></span><br></pre></td></tr></table></figure>
<p>Who doesn’t like <code>cowsay</code> ?</p>
<figure class="highlight bash"><figcaption><span>/etc/ansible/ansible.cfg</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># don't like cows?  that's unfortunate.</span></span><br><span class="line"><span class="comment"># set to 1 if you don't want cowsay support or export ANSIBLE_NOCOWS=1 </span></span><br><span class="line"><span class="comment">#nocows = 1</span></span><br></pre></td></tr></table></figure>
<p>The lines following these let you tweak and customise components of cowsay even further!</p>
<p>After which the remaining sections that have been omitted here contain more background areas of Ansible, should you need to examine or change them in the future.</p>
<figure class="highlight bash"><figcaption><span>/etc/ansible/ansible.cfg</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[privilege_escalation]</span><br><span class="line">&lt;...&gt;</span><br><span class="line">[paramiko_connection]</span><br><span class="line">&lt;...&gt;</span><br><span class="line">[ssh_connection]</span><br><span class="line">&lt;...&gt;</span><br><span class="line">[accelerate]</span><br><span class="line">&lt;...&gt;</span><br><span class="line">[selinux]</span><br><span class="line">&lt;...&gt;</span><br></pre></td></tr></table></figure>
<p>Any major changes or crucial updates to the configuration file syntax and formatting will likely be pushed to the GitHub development configuration file at:</p>
<blockquote>
<p><a href="https://raw.githubusercontent.com/ansible/ansible/devel/examples/ansible.cfg" target="_blank" rel="external">https://raw.githubusercontent.com/ansible/ansible/devel/examples/ansible.cfg</a></p>
</blockquote>
<p>Or shown in the official documentation. </p>
<hr>
<h1 id="7-–-Ansible-Temp-Directory-Permissions"><a href="#7-–-Ansible-Temp-Directory-Permissions" class="headerlink" title="7 – Ansible Temp Directory Permissions"></a>7 – Ansible Temp Directory Permissions</h1><p>Should the permissions and or ownership rights of the below directory become allocated to <em>root</em>, Ansible will not be able to write to this directory (and thereby fail to run).    </p>
<p><code>/home/$USER/.ansible/tmp/</code></p>
<p>Here’s how the permissions should look; substituted with your own Linux username.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">drwx------ 2 scarlz scarlz 4096 Jun 21 15:12 ./</span><br><span class="line">drwx------ 3 scarlz scarlz 4096 Jun 21 15:12 ../</span><br></pre></td></tr></table></figure>
<p>Simply make sure the user you are running Ansible as posseses sufficient permissions to utilise this directory. If this is not the case either alter the permissions with <code>chmod</code> / <code>chown</code> or failing that delete the directory then re-run Ansible.  </p>
<hr>
<iframe width="1080" height="500" src="https://www.youtube.com/embed/ZNB1at8mJWY" frameborder="1" allowfullscreen><br></iframe>

<p>What’s been covered in this post is the very basics of Ansible and only goes a short way towards demonstrating its ability as a configuration management tool. There are still a variety of pieces to fit into the puzzle such as modules, inventory items, and most importantly the playbooks. Which all make up and achieve the aims of the software described in the premable. </p>
<p>A future post on Ansible will look at more at the concept of “inventory”.</p>
<p><a href="http://www.tricksofthetrades.net/trades/">Links to subsequent Ansible posts can be found on the Trades page.</a></p>
<p><strong>More Information</strong></p>
<ul>
<li><a href="http://docs.ansible.com/ansible/intro_installation.html" target="_blank" rel="external">Official Ansible Documentation - Installation</a> – Extensive instructions for installing and building Ansible from source are located here. </li>
<li><a href="http://docs.ansible.com/ansible/intro_getting_started.html" target="_blank" rel="external">Official Ansible Documentation - Getting Started</a> – A few initial ad hoc commands and examples of them are described in brief here. </li>
<li><a href="http://docs.ansible.com/ansible/intro_configuration.html" target="_blank" rel="external">Official Ansible Documentation - Configuration File</a> – Anything and everything to do with the configuration file, good for referring back to.  </li>
</ul>
<blockquote>
<p>Easily deploy an SSD cloud server on <a href="https://www.digitalocean.com/?refcode=e91058dbfc7b" target="_blank" rel="external">Digital Ocean</a> in 55 seconds. Sign up using my link and receive $10.00 in free credit: <a href="https://www.digitalocean.com/?refcode=e91058dbfc7b" target="_blank" rel="external">https://www.digitalocean.com/?refcode=e91058dbfc7b</a></p>
</blockquote>
<p>– Scarlz: <a href="https://twitter.com/5car1z" target="_blank" rel="external">@5car1z</a></p>
</div><footer class="post__foot u-cf"><ul class="post__tag u-fl"><li class="post__tag__item"><a href="/tags/Ansible/" class="post__tag__link">Ansible</a></li><li class="post__tag__item"><a href="/tags/CM/" class="post__tag__link">CM</a></li><li class="post__tag__item"><a href="/tags/Python/" class="post__tag__link">Python</a></li></ul><a href="/2016/02/10/ansible-installing-running/#disqus_thread" class="post__foot-link u-fr">COMMENTS</a></footer></article><article class="post"><header class="post__head"><time datetime="2016-01-27T00:00:00.000Z" class="post__time">January 27, 2016</time><h1 class="post__title"><a href="/2016/01/27/docker-further-administration-networking/">Docker - Daemon Administration and Networking (3)</a></h1></header><div class="post__main echo"><p><img src="http://i.imgur.com/poo8Rai.png" alt="Docker Logo Image"></p>
<h1 id="Preamble"><a href="#Preamble" class="headerlink" title="Preamble"></a>Preamble</h1><p>This time we are beginning by centering around the Docker daemon and how it interacts with various process mangers from different platforms. Followed up by an introduction to networking in Docker that uses more of the Docker training images to link together and create a basic network of containers. Specifically a PostgreSQL database container and a Python webapp container.  </p>
<p>This is post three on Docker following on from <a href="http://www.tricksofthetrades.net/2016/01/07/docker-administration-applications/">Docker - Administration and Container Applications (2)</a>. If you’re looking for more generalised administration and basic example uses of the Docker Engine CLI then you may want to read that post instead. </p>
<a id="more"></a>
<hr>
<h1 id="1-–-Docker-Daemon-Administration"><a href="#1-–-Docker-Daemon-Administration" class="headerlink" title="1 – Docker Daemon Administration"></a>1 – Docker Daemon Administration</h1><p>The Docker daemon is the background service that handles running containers and all their states. </p>
<p>The starting and stopping of the Docker daemon is often configured through a process manager like systemd or Upstart. In a production environment this is very useful as you have a lot of customisable control over the behaviour of the daemon. </p>
<p>It can be run directly from the command line though instead of this:  </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker daemon</span><br></pre></td></tr></table></figure>
<p>It listens on the Unix socket - <code>unix:///var/run/docker.sock</code> when active and running. </p>
<p>If you’re running the docker daemon directly like this you can append configuration options to the command.</p>
<p>An example of running the docker <a href="https://docs.docker.com/engine/reference/commandline/daemon/" target="_blank" rel="external">daemon</a> with configuration options is as follows:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker daemon -D --tls=<span class="literal">true</span> --tlscert=/var/docker/server.pem --tlskey=/var/docker/serverkey.pem -H tcp://192.168.59.3:2376</span><br></pre></td></tr></table></figure>
<ul>
<li><code>-D</code> <code>--debug=false</code>    – Enable or disable debug mode. </li>
<li><code>--tls=false</code> – Enable or disable TLS. </li>
<li><code>--tlscert=</code> – certificate location. </li>
<li><code>tlskey=</code> – key location. </li>
<li><code>-H</code> <code>--host=[]</code> – Daemon socket(s) to connect to.</li>
</ul>
<p>More options are on offer for the Docker daemon at the link before the last code block. </p>
<h2 id="Upstart"><a href="#Upstart" class="headerlink" title="Upstart"></a>Upstart</h2><p>The default Docker daemon Upstart job is found in <code>/etc/init/docker.conf</code> .</p>
<p>To check the status of the daemon:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo status docker</span><br></pre></td></tr></table></figure>
<p>To start the Docker daemon:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo start docker</span><br></pre></td></tr></table></figure>
<p>Stop the Docker daemon:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo stop docker</span><br></pre></td></tr></table></figure>
<p>Or restart the daemon:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo restart docker</span><br></pre></td></tr></table></figure>
<p>Logs for Upstart jobs are found in <code>/var/log/upstart</code> and are compressed when the daemon is not running. So run the daemon/container to read the active log file - <code>docker.log</code> via:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo tail -fn 15 /var/<span class="built_in">log</span>/upstart/docker.log</span><br></pre></td></tr></table></figure>
<h2 id="systemd"><a href="#systemd" class="headerlink" title="systemd"></a>systemd</h2><p>Default unit files are stored in the subdirectories of <code>/usr/lib/systemd</code> and <code>/lib/systemd/system</code> . Custom user created unit files are kept in <code>/etc/systemd/system</code> .</p>
<p>To check the status of the daemon:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo systemctl status docker</span><br></pre></td></tr></table></figure>
<p>To start the Docker daemon:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo systemctl start docker</span><br></pre></td></tr></table></figure>
<p>Stop the Docker daemon:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo systemctl stop docker</span><br></pre></td></tr></table></figure>
<p>Or restart the daemon:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo systemctl restart docker</span><br></pre></td></tr></table></figure>
<p>To ensure the Docker daemon starts at boot:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo systemctl enable docker</span><br></pre></td></tr></table></figure>
<p>Logs for Docker are viewed in systemd with:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ journalctl -u docker</span><br></pre></td></tr></table></figure>
<p>A more in-depth look at systemd and Docker is kept here in the Docker docs:</p>
<blockquote>
<p><a href="https://docs.docker.com/engine/articles/systemd/" target="_blank" rel="external">Docker Documentation - systemd</a></p>
</blockquote>
<hr>
<h1 id="2-–-Process-Manager-Container-Automation"><a href="#2-–-Process-Manager-Container-Automation" class="headerlink" title="2 – Process Manager Container Automation"></a>2 – Process Manager Container Automation</h1><p><em>Restart policies</em> are an in-built Docker mechanism for restarting containers automatically when they exit. These must be set manually with the flag - <code>--restart=&quot;yes&quot;</code> and are also triggered when the Docker daemon starts up (like after a system reboot). Restart policies start linked containers in the correct order too. </p>
<p>If you have non-Docker processes that depend on Docker containers you can use a process manager like upstart, systemd or supervisor instead of these restart policies to replace this functionality. </p>
<p>This is what we will cover in this step.</p>
<blockquote>
<p><strong>Note:</strong> Be aware that process mangers will conflict with Docker restart policies if they are both in action So don’t run restart policies if you are using a process manager.</p>
</blockquote>
<p>For these examples assume that the container’s for each have already been created and are running Ghost with the name <code>--name=ghost-container</code> . </p>
<h2 id="Upstart-1"><a href="#Upstart-1" class="headerlink" title="Upstart"></a>Upstart</h2><figure class="highlight bash"><figcaption><span>/etc/init/ghost.conf</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">description <span class="string">"Ghost Blogging Container"</span></span><br><span class="line">author <span class="string">"Scarlz"</span></span><br><span class="line">start on filesystem and started docker</span><br><span class="line">stop on runlevel [!2345]</span><br><span class="line">respawn</span><br><span class="line">script</span><br><span class="line">  /usr/bin/docker start <span class="_">-a</span> ghost-container</span><br><span class="line">end script</span><br></pre></td></tr></table></figure>
<p>Docker automatically attaches the process manager to the running container, or starts it if needed with this setup.</p>
<p>All signals from Docker are also forwarded so that the process manager can detect when a container stops, to correctly restart it.</p>
<p>If you need to pass options to the containers (such as <code>--env</code>) then you’ll need to use <code>docker run</code> rather than <code>docker start</code> in the job configuration.</p>
<p>For Example: </p>
<figure class="highlight bash"><figcaption><span>/etc/init/ghost.conf</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">script</span><br><span class="line">  /usr/bin/docker run --env foo=bar --name ghost-container ghost</span><br><span class="line">end script</span><br></pre></td></tr></table></figure>
<p>This differs as it creates a new container using the <code>ghost</code> image every time the service is started and takes into account the extra options. </p>
<h2 id="systemd-1"><a href="#systemd-1" class="headerlink" title="systemd"></a>systemd</h2><figure class="highlight bash"><figcaption><span>/etc/systemd/system/ghost</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=Ghost Blogging Container</span><br><span class="line">Requires=docker.service</span><br><span class="line">After=docker.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Restart=always</span><br><span class="line">ExecStart=/usr/bin/docker start <span class="_">-a</span> ghost-container</span><br><span class="line">ExecStop=/usr/bin/docker stop -t 2 ghost-container</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=local.target</span><br></pre></td></tr></table></figure>
<p>Docker automatically attaches the process manager to the running container, or starts it if needed with this setup. </p>
<p>All signals from Docker are also forwarded so that the process manager can detect when a container stops, to correctly restart it.</p>
<p>If you need to pass options to the containers (such as <code>--env</code>), then you’ll need to use <code>docker run</code> rather than <code>docker start</code> in the job configuration.</p>
<p>For Example: </p>
<figure class="highlight bash"><figcaption><span>/etc/systemd/system/ghost</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ExecStart=/usr/bin/docker run --env foo=bar --name ghost-container ghost</span><br><span class="line">ExecStop=/usr/bin/docker stop -t 2 ghost-container ; /usr/bin/docker rm <span class="_">-f</span> ghost-container</span><br></pre></td></tr></table></figure>
<p>This differs as it creates a new container with the extra options every time the service is started, which stops and removes itself when the Docker service ends. </p>
<hr>
<h1 id="3-–-Docker-Networks"><a href="#3-–-Docker-Networks" class="headerlink" title="3 – Docker Networks"></a>3 – Docker Networks</h1><p>Network drivers allow containers to be linked together and networked. Docker comes with two default network drivers as part of the normal installation:</p>
<ul>
<li>The bridge driver.  </li>
<li>The overlay driver. </li>
</ul>
<p>These two drivers are replaceable with other third party drivers that perform more optimally in different situations. But for low end basic Docker use these given defaults are fine. </p>
<p>Docker also automatically includes three default networks with the base install:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker network ls</span><br></pre></td></tr></table></figure>
<p>Listing them as:</p>
<figure class="highlight bash"><figcaption><span>Output</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">NETWORK ID          NAME                DRIVER</span><br><span class="line">2d41f8bbf514        host                host                </span><br><span class="line">f9ee6308ecdd        bridge              bridge              </span><br><span class="line">49dab653f349        none                null</span><br></pre></td></tr></table></figure>
<p>The network named <code>bridge</code> is classed as a special network. Docker launches any and all containers in this network (unless told otherwise). </p>
<p>So if you currently you have containers running these will have been placed into the <code>bridge</code> network group. </p>
<p>Networks can be <a href="https://docs.docker.com/engine/reference/commandline/network_inspect/" target="_blank" rel="external">inspected</a> using the next command, where <code>bridge</code> is the network name to be inspected:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker network inspect bridge</span><br></pre></td></tr></table></figure>
<p>The output shows any and all configured directives for the network:</p>
<figure class="highlight bash"><figcaption><span>Output</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">"Name"</span>: <span class="string">"bridge"</span>,</span><br><span class="line">        <span class="string">"Id"</span>: <span class="string">"f9ee6308ecdd5dc5a588428469de1b7c475fdafdab49cfc33c1c3ac0bf0559ab"</span>,</span><br><span class="line">        <span class="string">"Scope"</span>: <span class="string">"local"</span>,</span><br><span class="line">        <span class="string">"Driver"</span>: <span class="string">"bridge"</span>,</span><br><span class="line">        <span class="string">"IPAM"</span>: &#123;</span><br><span class="line">            <span class="string">"Driver"</span>: <span class="string">"default"</span>,</span><br><span class="line">            <span class="string">"Config"</span>: [</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="string">"Subnet"</span>: <span class="string">"172.17.0.0/16"</span></span><br><span class="line">                &#125;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">"Containers"</span>: &#123;</span><br><span class="line">            <span class="string">"ff98b5ed01dd4323f0ce38af9b8cea2d49d0b1e194cf147a3a8f632278a11451"</span>: &#123;</span><br><span class="line">                <span class="string">"EndpointID"</span>: <span class="string">"b7c9fabcda00ccebd6523f76477b51eba00dd5d3f26940355139fff62d5576bb"</span>,</span><br><span class="line">                <span class="string">"MacAddress"</span>: <span class="string">"02:42:ac:11:00:02"</span>,</span><br><span class="line">                <span class="string">"IPv4Address"</span>: <span class="string">"172.17.0.2/16"</span>,</span><br><span class="line">                <span class="string">"IPv6Address"</span>: <span class="string">""</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">"Options"</span>: &#123;</span><br><span class="line">            <span class="string">"com.docker.network.bridge.default_bridge"</span>: <span class="string">"true"</span>,</span><br><span class="line">            <span class="string">"com.docker.network.bridge.enable_icc"</span>: <span class="string">"true"</span>,</span><br><span class="line">            <span class="string">"com.docker.network.bridge.enable_ip_masquerade"</span>: <span class="string">"true"</span>,</span><br><span class="line">            <span class="string">"com.docker.network.bridge.host_binding_ipv4"</span>: <span class="string">"0.0.0.0"</span>,</span><br><span class="line">            <span class="string">"com.docker.network.bridge.name"</span>: <span class="string">"docker0"</span>,</span><br><span class="line">            <span class="string">"com.docker.network.driver.mtu"</span>: <span class="string">"1500"</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>This <code>inspect</code> output changes as a network is altered and configured, how to do this is covered in later steps. </p>
<hr>
<h1 id="4-–-Creating-Docker-Networks"><a href="#4-–-Creating-Docker-Networks" class="headerlink" title="4 – Creating Docker Networks"></a>4 – Creating Docker Networks</h1><p>Networks are natural ways to isolate containers from other containers or other networks. The original default networks are not to be solely relied upon however. It’s better to create your own network groups.</p>
<p>Remember there are two default drivers and therefore two native network types; <code>bridge</code> and <code>overlay</code> . Bridge networks can only make use of one singular host to run the Docker Engine software. An overlay network differs in that it can incorporate multiple hosts into running the Docker software. </p>
<p>To make the simpler “bridge” type network we use the <code>create</code> option:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker network create <span class="_">-d</span> bridge &lt;new-network-name&gt;</span><br></pre></td></tr></table></figure>
<p>With this last command the <code>-d</code> (driver) and <code>bridge</code> option specifies the network type we want to create. With a new name for the network at the end of the command. </p>
<p>To see the new network after creation:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker network ls</span><br></pre></td></tr></table></figure>
<p>Shown on the last line:</p>
<figure class="highlight bash"><figcaption><span>Output</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">NETWORK ID          NAME                  DRIVER</span><br><span class="line">f9ee6308ecdd        bridge                bridge              </span><br><span class="line">49dab653f349        none                  null                </span><br><span class="line">2d41f8bbf514        host                  host                </span><br><span class="line">08f44ef7de28        <span class="built_in">test</span>-bridge-network   bridge</span><br></pre></td></tr></table></figure>
<p>Overlay networks are a much wider topic due to their inclusion of multiple hosts so aren’t covered in this post but the basic principles and where to start is mentioned in the link below:    </p>
<blockquote>
<p><a href="https://docs.docker.com/engine/userguide/networking/work-with-networks/" target="_blank" rel="external">Docker Documentation - Working with Network Commands</a></p>
</blockquote>
<hr>
<h1 id="5-–-Connecting-Containers-to-Networks"><a href="#5-–-Connecting-Containers-to-Networks" class="headerlink" title="5 – Connecting Containers to Networks"></a>5 – Connecting Containers to Networks</h1><p>Creating and using these networks allows container applications to to operate in unison and as securely as possible. Containers inside of networks can only interact with their counterparts and are isolated from the outsides of the network. Similar to VLAN segregation inside of a IP based network.    </p>
<p>Usually containers are added to a network when you first launch and run the container. We’ll follow the example from the Docker Documentation that uses a PostgreSQL database container and the Python webapp to demonstrate a simple network configuration. </p>
<p>First launch a container running the PostgreSQL database training image, and in the process add it to your custom made bridge network from the previous step. </p>
<p>To do this we must pass the <code>--net=</code> flag to the new container, and provide it with the name of our custom bridge network. Which in my example earlier was <code>test-bridge-network</code> :  </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run <span class="_">-d</span> --net=<span class="built_in">test</span>-bridge-network --name db training/postgres</span><br></pre></td></tr></table></figure>
<p>You can inspect this aptly named <code>db</code> container to see where exactly it is connected:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker inspect --format=<span class="string">'&#123;&#123;json .NetworkSettings.Networks&#125;&#125;'</span> db</span><br></pre></td></tr></table></figure>
<p>This shows us the network details for the database container’s <code>test-bridge-network</code> connection:</p>
<figure class="highlight bash"><figcaption><span>Output</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">"test-bridge-network"</span>:&#123;<span class="string">"EndpointID"</span>:<span class="string">"0008c8566542ef24e5e57d5911c8e33a79f0fcb91b1bbdd60d5cdec3217fb517"</span>,<span class="string">"Gateway"</span>:<span class="string">"172.18.0.1"</span>,<span class="string">"IPAddress"</span>:<span class="string">"172.18.0.2"</span>,<span class="string">"IPPrefixLen"</span>:16,<span class="string">"IPv6Gateway"</span>:<span class="string">""</span>,<span class="string">"GlobalIPv6Address"</span>:<span class="string">""</span>,<span class="string">"GlobalIPv6PrefixLen"</span>:0,<span class="string">"MacAddress"</span>:<span class="string">"02:42:ac:12:00:02"</span>&#125;&#125;</span><br></pre></td></tr></table></figure>
<p>Next run the Python training web application in daemonised mode with out any extra options:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run <span class="_">-d</span> --name python-webapp training/webapp python app.py</span><br></pre></td></tr></table></figure>
<p>Inspect the <code>python-webapp</code> container’s network connection in the same way as before: </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker inspect --format=<span class="string">'&#123;&#123;json .NetworkSettings.Networks&#125;&#125;'</span> python-webapp</span><br></pre></td></tr></table></figure>
<p>As expected this new container is running under the <strong>default</strong> bridge network, shown in the output of the last command:</p>
<figure class="highlight bash"><figcaption><span>Output</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">"bridge"</span>:&#123;<span class="string">"EndpointID"</span>:<span class="string">"e5c7f1c8d097fdafc35b89d7bce576fe01a22709424643505d79abe394a59767"</span>,<span class="string">"Gateway"</span>:<span class="string">"172.17.0.1"</span>,<span class="string">"IPAddress"</span>:<span class="string">"172.17.0.2"</span>,<span class="string">"IPPrefixLen"</span>:16,<span class="string">"IPv6Gateway"</span>:<span class="string">""</span>,<span class="string">"GlobalIPv6Address"</span>:<span class="string">""</span>,<span class="string">"GlobalIPv6PrefixLen"</span>:0,<span class="string">"MacAddress"</span>:<span class="string">"02:42:ac:11:00:02"</span>&#125;&#125;</span><br></pre></td></tr></table></figure>
<p>Docker lets us connect a container to as many networks as we like. More importantly for us we can also connect an already running container to a network. </p>
<p>Attach the running <code>python-webapp</code> container to the “test-bridge-network” like we need:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker network connect test-bridge-network python-webapp</span><br></pre></td></tr></table></figure>
<p>To test the container connections to our custom network we can ping from one to the other.</p>
<p>Get the IP address of the <code>db</code> container:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker inspect --format=<span class="string">'&#123;&#123;range .NetworkSettings.Networks&#125;&#125;&#123;&#123;.IPAddress&#125;&#125;&#123;&#123;end&#125;&#125;'</span> db</span><br></pre></td></tr></table></figure>
<p>In my case this was:</p>
<figure class="highlight bash"><figcaption><span>Output</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">172.18.0.2</span><br></pre></td></tr></table></figure>
<p>Now we have the IP address open an interactive shell into the <code>python-webapp</code> container:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker <span class="built_in">exec</span> -it python-webapp bash</span><br></pre></td></tr></table></figure>
<p>Attempt to ping the <code>db</code> container with the IP address from before, substituting <code>172.18.0.2</code>  for your address equivalent:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ping -c 10 172.18.0.2</span><br></pre></td></tr></table></figure>
<p>As long as you successfully connected both containers earlier on, the ping command will be successful:</p>
<figure class="highlight bash"><figcaption><span>Output</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">root@<span class="built_in">fc</span>0f73c129c0:/opt/webapp<span class="comment"># ping -c 10 db</span></span><br><span class="line">PING db (172.18.0.2) 56(84) bytes of data.</span><br><span class="line">64 bytes from db (172.18.0.2): icmp_seq=1 ttl=64 time=0.216 ms</span><br><span class="line">64 bytes from db (172.18.0.2): icmp_seq=2 ttl=64 time=0.059 ms</span><br><span class="line">64 bytes from db (172.18.0.2): icmp_seq=3 ttl=64 time=0.053 ms</span><br><span class="line">64 bytes from db (172.18.0.2): icmp_seq=4 ttl=64 time=0.063 ms</span><br><span class="line">64 bytes from db (172.18.0.2): icmp_seq=5 ttl=64 time=0.065 ms</span><br><span class="line">64 bytes from db (172.18.0.2): icmp_seq=6 ttl=64 time=0.063 ms</span><br><span class="line">64 bytes from db (172.18.0.2): icmp_seq=7 ttl=64 time=0.062 ms</span><br><span class="line">64 bytes from db (172.18.0.2): icmp_seq=8 ttl=64 time=0.064 ms</span><br><span class="line">64 bytes from db (172.18.0.2): icmp_seq=9 ttl=64 time=0.061 ms</span><br><span class="line">64 bytes from db (172.18.0.2): icmp_seq=10 ttl=64 time=0.063 ms</span><br><span class="line"></span><br><span class="line">--- db ping statistics ---</span><br><span class="line">10 packets transmitted, 10 received, 0% packet loss, time 8997ms</span><br><span class="line">rtt min/avg/max/mdev = 0.053/0.076/0.216/0.047 ms</span><br></pre></td></tr></table></figure>
<p>Conveniently container names work in the place of an IP address too in this scenario:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ping -c 10 db</span><br></pre></td></tr></table></figure>
<p>Press <code>CTRL</code> + <code>D</code> to exit the container prompt, or type in <code>exit</code> instead. </p>
<p>And with that we have two containers on the same user created network able to communicate with each other, and able to share data. Which is what we would be aiming for in the case of the PostgreSQL database and Python webapp.  </p>
<p>There’s more ways of sharing data between containers once they are connected through a network, but these are covered in the next post of the series. </p>
<hr>
<h1 id="6-–-Miscellaneous-Networking-Commands"><a href="#6-–-Miscellaneous-Networking-Commands" class="headerlink" title="6 – Miscellaneous Networking Commands"></a>6 – Miscellaneous Networking Commands</h1><p>Here are a few complimentary commands in relation to what has already been covered in this post.</p>
<p>At some point you are likely to need to remove a container from its network. This is done by using the <code>disconnect</code> command:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker network disconnect <span class="built_in">test</span>-bridge-network &lt;container-name&gt;</span><br></pre></td></tr></table></figure>
<p>Here <code>test-bridge-network</code> is the name of the network, followed by which container you want to remove from it. </p>
<p>When all the containers in a network are stopped or disconnected, you can remove networks themselves completely with:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker network rm <span class="built_in">test</span>-bridge-network</span><br></pre></td></tr></table></figure>
<p>Meaning the <code>test-bridge-network</code> is now deleted and absent from the list of existing networks:</p>
<figure class="highlight bash"><figcaption><span>Output</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">NETWORK ID          NAME                  DRIVER             </span><br><span class="line">2e38b3a44489        bridge                bridge              </span><br><span class="line">79d9d21edbec        none                  null                </span><br><span class="line">61371e641e1b        host                  host</span><br></pre></td></tr></table></figure>
<p>The output here is garnered from the <code>docker network ls</code> command. </p>
<hr>
<p>Networking in Docker begins here with these examples but goes a lot further than what we’ve covered. Data volumes, data containers, and mounting host volumes are described in the next post on Docker when it’s released. </p>
<p><a href="http://www.tricksofthetrades.net/trades/">Links to subsequent Docker posts can be found on the Trades page.</a></p>
<p><strong>More Information</strong></p>
<ul>
<li><a href="https://docs.docker.com/engine/articles/configuring/" target="_blank" rel="external">Docker Docs - Configuring and Running Docker on Various Distributions</a> – Covers the daemon setup and is the main source for the first few steps of this post.  </li>
<li><a href="https://docs.docker.com/engine/articles/host_integration/" target="_blank" rel="external">Docker Docs -Automatically Start Containers</a> – Is mostly step 2 and has the bases for the process manger uptime script examples. </li>
<li><a href="https://docs.docker.com/engine/userguide/networking/" target="_blank" rel="external">Docker Docs - Networking Containers</a> – Anything and everything networking wise in this post comes from this. </li>
</ul>
<blockquote>
<p>Easily deploy an SSD cloud server on <a href="https://www.digitalocean.com/?refcode=e91058dbfc7b" target="_blank" rel="external">Digital Ocean</a> in 55 seconds. Sign up using my link and receive $10.00 in free credit: <a href="https://www.digitalocean.com/?refcode=e91058dbfc7b" target="_blank" rel="external">https://www.digitalocean.com/?refcode=e91058dbfc7b</a></p>
</blockquote>
<p>– Scarlz: <a href="https://twitter.com/5car1z" target="_blank" rel="external">@5car1z</a></p>
</div><footer class="post__foot u-cf"><ul class="post__tag u-fl"><li class="post__tag__item"><a href="/tags/Docker/" class="post__tag__link">Docker</a></li><li class="post__tag__item"><a href="/tags/Containers/" class="post__tag__link">Containers</a></li><li class="post__tag__item"><a href="/tags/Virtualisation/" class="post__tag__link">Virtualisation</a></li></ul><a href="/2016/01/27/docker-further-administration-networking/#disqus_thread" class="post__foot-link u-fr">COMMENTS</a></footer></article></main><footer class="foot"><div class="foot-copy u-fl">&copy; 2018 Scarlz</div><menu class="page-menu u-fr"><li class="page-menu__item"><a title="Previous" href="/trades/Programming/page/2/" class="page-menu__link icon-arrow-left"></a></li><li class="page-menu__item"><a title="Next" href="/trades/Programming/page/4/" class="page-menu__link icon-arrow-right"></a></li></menu></footer><script>(function(h,g,l,k,j,i){j=h.createElement(g),i=h.getElementsByTagName(g)[0],
j.src="//"+l+".disqus.com/"+k+".js",i.parentNode.insertBefore(j,i)})
(document,"script","totts","count");
</script></body></html>